{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP 3A - Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Louis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Baseline code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The team scored a last-minute goal to win the ...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The tennis player served an ace to win the match.</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The basketball game went into overtime, but th...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The marathon runner broke the world record wit...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The soccer match ended in a draw after a thril...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  The team scored a last-minute goal to win the ...  Sports\n",
       "1  The tennis player served an ace to win the match.  Sports\n",
       "2  The basketball game went into overtime, but th...  Sports\n",
       "3  The marathon runner broke the world record wit...  Sports\n",
       "4  The soccer match ended in a draw after a thril...  Sports"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('test.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "f_data = {}\n",
    "for k, v in data.items():\n",
    "    f_data[k] = v[:95] # Ok, en gros f_date = {'Sport': [Liste des sequences de theme sport],...}\n",
    "\n",
    "processed_data = {\n",
    "    'text': [], 'target': []\n",
    "}\n",
    "for k, v in f_data.items():\n",
    "    processed_data['text'] += v\n",
    "    processed_data['target'] += [k] * len(v) # {'text': [Liste des phrases], 'target': [Liste des labels]}\n",
    "\n",
    "df_test = pd.DataFrame.from_dict(processed_data)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a long, short one. The longer you write it the...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm not an expert on the political world. I ju...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't care what the government thinks, but I...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The last time I talked to an old man, he was t...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What do you mean by the term politics? Do we t...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    target\n",
       "0  a long, short one. The longer you write it the...  Politics\n",
       "1  I'm not an expert on the political world. I ju...  Politics\n",
       "2  I don't care what the government thinks, but I...  Politics\n",
       "3  The last time I talked to an old man, he was t...  Politics\n",
       "4  What do you mean by the term politics? Do we t...  Politics"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('cleaned_generated_train.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "f_data = {}\n",
    "for k, v in data.items():\n",
    "    f_data[k] = v[:95] # Ok, en gros f_date = {'Sport': [Liste des sequences de theme sport],...}\n",
    "\n",
    "processed_data = {\n",
    "    'text': [], 'target': []\n",
    "}\n",
    "for k, v in f_data.items():\n",
    "    processed_data['text'] += v\n",
    "    processed_data['target'] += [k] * len(v) # {'text': [Liste des phrases], 'target': [Liste des labels]}\n",
    "\n",
    "df = pd.DataFrame.from_dict(processed_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The mayor announced a new initiative to improv...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The senator is facing criticism for her stance...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The upcoming election has sparked intense deba...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regular exercise and a balanced diet are key t...</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The World Health Organization has issued new g...</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    target\n",
       "0  The mayor announced a new initiative to improv...  Politics\n",
       "1  The senator is facing criticism for her stance...  Politics\n",
       "2  The upcoming election has sparked intense deba...  Politics\n",
       "3  Regular exercise and a balanced diet are key t...    Health\n",
       "4  The World Health Organization has issued new g...    Health"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('train.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "f_data = {}\n",
    "for k, v in data.items():\n",
    "    f_data[k] = v[:95] # Ok, en gros f_date = {'Sport': [Liste des sequences de theme sport],...}\n",
    "\n",
    "processed_data = {\n",
    "    'text': [], 'target': []\n",
    "}\n",
    "for k, v in f_data.items():\n",
    "    processed_data['text'] += v\n",
    "    processed_data['target'] += [k] * len(v) # {'text': [Liste des phrases], 'target': [Liste des labels]}\n",
    "\n",
    "df = pd.DataFrame.from_dict(processed_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\ufffd' in position 80: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_shuffle.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m X_train\u001b[38;5;241m.\u001b[39mtolist():\n\u001b[1;32m----> 9\u001b[0m         file\u001b[38;5;241m.\u001b[39mwrite(item \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test_shuffle.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m y_train\u001b[38;5;241m.\u001b[39mtolist():\n",
      "File \u001b[1;32mc:\\Users\\Louis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\encodings\\cp1252.py:19\u001b[0m, in \u001b[0;36mIncrementalEncoder.encode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_encode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,encoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\ufffd' in position 80: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df['text'].values, df['target'].values, test_size=0,\n",
    "#                                                    random_state=123, stratify=df['target'].values)\n",
    "\n",
    "X_train = df['text'].values\n",
    "y_train = df['target'].values\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "with open('test_shuffle.txt', 'w') as file:\n",
    "    for item in X_train.tolist():\n",
    "        file.write(item + \"\\n\")\n",
    "\n",
    "with open('y_test_shuffle.txt', 'w') as file:\n",
    "    for item in y_train.tolist():\n",
    "        file.write(item + \"\\n\")\n",
    "\n",
    "y_test = df_test['target'].values\n",
    "X_test = df_test['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - TfidfVectorizer + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m----> 2\u001b[0m tfidf_train_vectors \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m)\n\u001b[0;32m      3\u001b[0m tfidf_test_vectors \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m      5\u001b[0m classifier \u001b[38;5;241m=\u001b[39m RandomForestClassifier() \u001b[38;5;66;03m# RF baseline model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_train_vectors = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test_vectors = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "classifier = RandomForestClassifier() # RF baseline model\n",
    "classifier.fit(tfidf_train_vectors, y_train)\n",
    "\n",
    "y_pred = classifier.predict(tfidf_test_vectors)\n",
    "\n",
    "\n",
    "with open('y_pred_shuffle.txt', 'w') as file:\n",
    "    for item in y_pred.tolist():\n",
    "        file.write(item + \"\\n\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Sentence': X_test,\n",
    "    'Actual Target': y_test,\n",
    "    'Predicted Target': y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique labels is: 12\n"
     ]
    }
   ],
   "source": [
    "num_unique_labels = df['target'].nunique()\n",
    "print(f'The number of unique labels is: {num_unique_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=12).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.sentences[index]\n",
    "        label = self.labels[index]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 128\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "train_dataset = SentenceDataset(X_train, y_train_encoded, tokenizer, MAX_LEN)\n",
    "test_dataset = SentenceDataset(X_test, y_test_encoded, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), torch.mean(torch.tensor(losses))\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), torch.mean(torch.tensor(losses)), all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_acc, train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    val_acc, val_loss, _, _ = eval_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18070175438596492"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_bert = pd.DataFrame({\n",
    "    'Sentence': X_test,\n",
    "    'Actual Target': y_test,\n",
    "    'Predicted Target': y_pred\n",
    "})\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III - Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Actual Target</th>\n",
       "      <th>Predicted Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The team scored a last-minute goal to win the ...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The tennis player served an ace to win the match.</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The basketball game went into overtime, but th...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The marathon runner broke the world record wit...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The soccer match ended in a draw after a thril...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Actual Target  \\\n",
       "0  The team scored a last-minute goal to win the ...        Sports   \n",
       "1  The tennis player served an ace to win the match.        Sports   \n",
       "2  The basketball game went into overtime, but th...        Sports   \n",
       "3  The marathon runner broke the world record wit...        Sports   \n",
       "4  The soccer match ended in a draw after a thril...        Sports   \n",
       "\n",
       "  Predicted Target  \n",
       "0         Politics  \n",
       "1         Politics  \n",
       "2           Travel  \n",
       "3           Sports  \n",
       "4          Fashion  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_bert.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Actual Target</th>\n",
       "      <th>Predicted Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The team scored a last-minute goal to win the ...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The tennis player served an ace to win the match.</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The basketball game went into overtime, but th...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The marathon runner broke the world record wit...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The soccer match ended in a draw after a thril...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Actual Target  \\\n",
       "0  The team scored a last-minute goal to win the ...        Sports   \n",
       "1  The tennis player served an ace to win the match.        Sports   \n",
       "2  The basketball game went into overtime, but th...        Sports   \n",
       "3  The marathon runner broke the world record wit...        Sports   \n",
       "4  The soccer match ended in a draw after a thril...        Sports   \n",
       "\n",
       "  Predicted Target  \n",
       "0         Politics  \n",
       "1         Politics  \n",
       "2           Travel  \n",
       "3           Sports  \n",
       "4          Fashion  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Label to submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_pred_shuffle.txt', 'r') as file:\n",
    "    datas = file.readlines()\n",
    "\n",
    "with open('y_test_shuffle_for_kaggle.txt', 'w') as file:\n",
    "    i = 0\n",
    "    file.write(f\"ID,Usage,Label\\n\")\n",
    "    for data in datas:\n",
    "        file.write(f\"{i},Private,{data}\") if i % 2 == 1 else file.write(f\"{i},Public,{data}\")\n",
    "        i += 1\n",
    "\n",
    "with open('y_test_shuffle.txt', 'r') as file:\n",
    "    datas = file.readlines()\n",
    "\n",
    "with open('y_test_shuffle_for_kaggle.txt', 'w') as file:\n",
    "    i = 0\n",
    "    file.write(f\"ID,Usage,Label\\n\")\n",
    "    for data in datas:\n",
    "        file.write(f\"{i},Private,{data}\")\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
